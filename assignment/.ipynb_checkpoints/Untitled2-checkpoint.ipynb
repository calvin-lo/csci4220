{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeLMfilters():\n",
    "    SUP = 49\n",
    "    SCALEX = [np.sqrt(2), np.power(np.sqrt(2),2), np.power(np.sqrt(2),3)]\n",
    "    NORIENT = 6\n",
    "    NROTINV = 12\n",
    "    \n",
    "    NBAR = len(SCALEX) * NORIENT\n",
    "    NEDGE = len(SCALEX) * NORIENT\n",
    "    NF = NBAR + NEDGE + NROTINV\n",
    "    F = np.zeros((SUP, SUP, NF))\n",
    "    hsup = (SUP)/2\n",
    "    x, y = np.meshgrid(np.linspace(-hsup, hsup, hsup*2+1), np.linspace(hsup, -hsup, hsup*2+1))\n",
    "    xx = []\n",
    "    yy = []\n",
    "    for i in range(0, SUP):\n",
    "        for j in range(0, SUP):\n",
    "            xx.append(x[j][i])\n",
    "            yy.append(y[j][i])\n",
    "            \n",
    "    orgpts = np.transpose(np.transpose([xx, yy]))\n",
    "    \n",
    "    count = 0;\n",
    "    for scale in range(0, len(SCALEX)):\n",
    "        for orient in range (0,NORIENT):\n",
    "            angle = np.pi * orient/NORIENT\n",
    "            c = np.cos(angle)\n",
    "            s = np.sin(angle)\n",
    "            rotpts =  np.dot([[c,-s],[s,c]], orgpts)\n",
    "            rotpts = np.asarray(rotpts)\n",
    "            F[:,:,count]=makefilter_LM(SCALEX[scale],0,1,rotpts,SUP)\n",
    "            F[:,:,count+NEDGE]=makefilter_LM(SCALEX[scale],0,2,rotpts,SUP)\n",
    "            count=count+1\n",
    "    \n",
    "    count = NBAR + NEDGE\n",
    "    SCALES = np.power(np.sqrt(2),[1,2,3,4])\n",
    "    for i in range(0,len(SCALES)):\n",
    "        F[:,:,count] = normalise(gauss_kernel((SUP, SUP), SCALES[i]))\n",
    "        F[:,:,count+1] =normalise(log_kernel(SUP,SCALES[i]))\n",
    "        F[:,:,count+2] = normalise(log_kernel(SUP,3*SCALES[i]))\n",
    "        count=count+3;\n",
    "        \n",
    "    return F\n",
    "\n",
    "def makefilter_LM(scale, phasex, phasey, pts, sup):\n",
    "    gx = gauss1d(3*scale, 0, pts[0,:], phasex)\n",
    "    gy = gauss1d(scale, 0, pts[1,:], phasey)\n",
    "    f = normalise(np.reshape(gx*gy, (sup, sup)))\n",
    "    return f\n",
    "\n",
    "def gauss1d(sigma, mean, x, ord):\n",
    "    x = x - mean\n",
    "    num = x * x\n",
    "    variance = np.power(sigma,2)\n",
    "    denom = 2 * variance\n",
    "    g = np.exp(-num/denom)/np.power((np.pi*denom), 0.5)\n",
    "    if ord == 1:\n",
    "        g = -g * (x/variance)\n",
    "    elif ord == 2:\n",
    "        g = g * ((num-variance)/np.power(variance,2))\n",
    "    return g\n",
    "                 \n",
    "def normalise(f):\n",
    "    f = f - np.mean(f[:])\n",
    "    f = f/np.sum(np.abs(f[:]))\n",
    "    return f\n",
    "\n",
    "def gauss_kernel(shape=(3,3),sigma=0.5):\n",
    "    m,n = [(ss-1.)/2. for ss in shape]\n",
    "    y,x = np.ogrid[-m:m+1,-n:n+1]\n",
    "    h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )\n",
    "    h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "    return h\n",
    "\n",
    "def log_kernel(p2, sigma):\n",
    "    rows = p2\n",
    "    cols = p2\n",
    "    \n",
    "    r2 = (rows-1)/2\n",
    "    c2 = (cols-1)/2\n",
    "\n",
    "    x, y = np.meshgrid(np.linspace(-c2,c2, c2*2 + 1), np.linspace(-r2,r2, r2*2 + 1))\n",
    "    radsqrd = np.power(x,2) + np.power(y,2)\n",
    "    \n",
    "    f = -1 / (np.pi * np.power(sigma,4))* (1 - radsqrd / 2 * np.power(sigma,2))*np.exp(-radsqrd/2*np.power(sigma,2))\n",
    "    f = f - np.mean(f)\n",
    "    \n",
    "    return f\n",
    "def log_ker(p2,p3):\n",
    "    siz   = (p2-1)/2\n",
    "    std2   = np.power(p3,2)\n",
    "\n",
    "    x,y = np.meshgrid(np.linspace(-siz,siz, 2 * siz + 1), np.linspace(-siz, siz, 2 * siz +1))\n",
    "    arg   = -(x*x + y*y)/(2*std2)\n",
    "\n",
    "    h = np.exp(arg)\n",
    "    eps = 0.00000000000000001\n",
    "    h[h<eps*np.max(h)] = 0\n",
    "\n",
    "    sumh = np.sum(h)\n",
    "      \n",
    "    if sumh != 0:\n",
    "        h  = h/sumh\n",
    "      \n",
    "    h1 = h*(x*x + y*y - 2*std2)/np.power(std2,2)\n",
    "    h = h1 - np.sum(h1)/np.prod(p2)\n",
    "      \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LM_convolve(file1, file2):\n",
    "    LM = makeLMfilters()\n",
    "    \n",
    "    LM_img1 = cv2.imread(file1)\n",
    "    LM_img1 = cv2.cvtColor(LM_img1, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    LM_img2 = cv2.imread(file2)\n",
    "    LM_img2 = cv2.cvtColor(LM_img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    LM_response1 = []\n",
    "    LM_response2 = []\n",
    "    \n",
    "    for i in range(0,48):\n",
    "        LM_response1.append(np.abs(signal.convolve(LM_img1, LM[:,:,i], mode='valid')))\n",
    "        LM_response2.append(np.abs(signal.convolve(LM_img2, LM[:,:,i], mode='valid')))\n",
    "    \n",
    "    return LM_response1, LM_response2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LM_calculate(LM_response1, LM_response2):\n",
    "    for i in range(0,13):\n",
    "        LM_m1, LM_s1 = cv2.meanStdDev(LM_response1[i])\n",
    "        LM_means1.append(LM_m1[0][0])\n",
    "        LM_std1.append(LM_s1[0][0])\n",
    "        LM_avg1.append(np.average(LM_response1[i]))\n",
    "        \n",
    "        LM_m2, LM_s2 = cv2.meanStdDev(LM_response2[i])\n",
    "        LM_means2.append(LM_m2[0][0])\n",
    "        LM_std2.append(LM_s2[0][0])\n",
    "        LM_avg2.append(np.average(LM_response2[i]))\n",
    "        \n",
    "    LM_means1 = np.asarray(LM_means1)\n",
    "    means2 = np.asarray(LM_means2)\n",
    "    LM_std1 = np.asarray(LM_std1)\n",
    "    LM_std2 = np.asarray(LM_std2)\n",
    "    LM_avg1 = np.asarray(LM_avg1)\n",
    "    LM_avg2 = np.asarray(LM_avg2)\n",
    "        \n",
    "    LM_means_distance = np.sqrt(np.sum((LM_means1-LM_means2)**2))\n",
    "    LM_std_distance = np.sqrt(np.sum((LM_std1-LM_std2)**2))\n",
    "    LM_avg_distance = np.sqrt(np.sum((LM_avg1-LM_avg2)**2))\n",
    "    \n",
    "    return (LM_means_distance, LM_td_distance, LM_avg_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textureAnalysisLM(file1, file2):\n",
    "    LM = makeLMfilters()\n",
    "    \n",
    "    LM_img1 = cv2.imread(file1)\n",
    "    LM_img1 = cv2.cvtColor(LM_img1, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    LM_img2 = cv2.imread(file2)\n",
    "    LM_img2 = cv2.cvtColor(LM_img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    LM_response1 = []\n",
    "    LM_response2 = []\n",
    "    \n",
    "    for i in range(0,48):\n",
    "        LM_response1.append(np.abs(signal.convolve(LM_img1, LM[:,:,i], mode='valid')))\n",
    "        LM_response2.append(np.abs(signal.convolve(LM_img2, LM[:,:,i], mode='valid')))\n",
    "        \n",
    "    LM_means1 = []\n",
    "    LM_std1 = []\n",
    "    LM_avg1 = []\n",
    "    LM_means2 = []\n",
    "    LM_std2 = []\n",
    "    LM_avg2 = []\n",
    "    \n",
    "    for i in range(0,13):\n",
    "        LM_m1, LM_s1 = cv2.meanStdDev(LM_response1[i])\n",
    "        LM_means1.append(LM_m1[0][0])\n",
    "        LM_std1.append(LM_s1[0][0])\n",
    "        LM_avg1.append(np.average(LM_response1[i]))\n",
    "        \n",
    "        LM_m2, LM_s2 = cv2.meanStdDev(LM_response2[i])\n",
    "        LM_means2.append(LM_m2[0][0])\n",
    "        LM_std2.append(LM_s2[0][0])\n",
    "        LM_avg2.append(np.average(LM_response2[i]))\n",
    "        \n",
    "    LM_means1 = np.asarray(LM_means1)\n",
    "    means2 = np.asarray(LM_means2)\n",
    "    LM_std1 = np.asarray(LM_std1)\n",
    "    LM_std2 = np.asarray(LM_std2)\n",
    "    LM_avg1 = np.asarray(LM_avg1)\n",
    "    LM_avg2 = np.asarray(LM_avg2)\n",
    "        \n",
    "    LM_means_distance = np.sqrt(np.sum((LM_means1-LM_means2)**2))\n",
    "    LM_std_distance = np.sqrt(np.sum((LM_std1-LM_std2)**2))\n",
    "    LM_avg_distance = np.sqrt(np.sum((LM_avg1-LM_avg2)**2))\n",
    "    \n",
    "    return (LM_means_distance, LM_td_distance, LM_avg_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print textureAnalysisLM('stained_0.jpg', 'stained_1.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print textureAnalysisLM('stained_0.jpg', 'stained_1.jpg') \n",
    "print textureAnalysisLM('stained_0.jpg', 'stained_2.jpg') \n",
    "print textureAnalysisLM('stained_0.jpg', 'bumpy_0.jpg') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
